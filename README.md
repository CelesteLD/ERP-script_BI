# M√≥dulo de ingesta y dimulaci√≥n ERP - Proyecto BI Desempleo Juvenil Canarias

## üìë Prop√≥sito del repositorio

Este repositorio contiene el motor de ingesta de datos desarrollado para el **Proyecto de Business Intelligence sobre el Desempleo Juvenil en Canarias**. El script act√∫a como el primer eslab√≥n del pipeline de datos, simulando un sistema transaccional de una organizaci√≥n real a partir de fuentes de datos abiertas del **ISTAC**.

El objetivo primordial es poner en valor la metodolog√≠a utilizada y el rigor en el tratamiento de la informaci√≥n desde su origen. Este componente ha sido dise√±ado para:

* **Simulaci√≥n del entorno operacional**: Act√∫a como el sistema de origen (`bd_erp`), recreando c√≥mo una organizaci√≥n recolectar√≠a sus registros brutos antes de ser procesados en el Data Warehouse.
* **Automatizaci√≥n de la ingesta**: Descarga y normaliza autom√°ticamente los datasets definidos en la configuraci√≥n centralizada, integrando fuentes de Paro Registrado, EPA y Tasas de Inserci√≥n.
* **Garant√≠a de trazabilidad**: Implementa un registro de auditor√≠a (`erp_ingest_log`) para monitorizar la carga y asegurar la calidad del dato desde la fase inicial.

## üõ†Ô∏è Stack tecnol√≥gico

El desarrollo se sustenta en una arquitectura de datos moderna y escalable:

* **Lenguaje**: Python 3.x para la generaci√≥n de scripts y descarga de datos mediante APIs.
* **Base de datos**: PostgreSQL, que desempe√±a el rol de base de datos operacional simulada (`bd_erp`).
* **L√≥gica de configuraci√≥n**: YAML para la definici√≥n estructurada de los datasets y sus metadatos.
* **Seguridad**: Gesti√≥n de credenciales mediante variables de entorno (`.env`).

## ‚öôÔ∏è Funcionalidades del script

### 1. Normalizaci√≥n y estandarizaci√≥n
El script incluye funciones de "sanitizaci√≥n" (`snake_case`) que transforman los encabezados originales en nombres de columna normalizados. Esto facilita la posterior integraci√≥n con herramientas de transformaci√≥n como **dbt**.

### 2. Gesti√≥n automatizada de infraestructura
Utiliza l√≥gica de "infraestructura como c√≥digo" para:
* Verificar la existencia de la base de datos y crearla con codificaci√≥n UTF-8 si es necesario.
* Recrear las tablas de forma din√°mica (capa `Raw`) bas√°ndose en la estructura detectada en los archivos CSV.

### 3. Carga de datos eficiente
Implementa el m√©todo `copy_expert` de PostgreSQL para realizar una carga masiva de datos (bulk load) desde STDIN, asegurando un rendimiento √≥ptimo en comparaci√≥n con inserciones fila por fila.

## üöÄ Gu√≠a de uso

1. **Configuraci√≥n**: Definir las credenciales en el archivo `.env`.
2. **Definici√≥n**: Listar los datasets deseados en `datasets.yaml`.
3. **Ejecuci√≥n**:
   ```bash
   python main.py